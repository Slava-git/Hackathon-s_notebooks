{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification",
      "provenance": [],
      "collapsed_sections": [
        "eFxgLV5HAEEw",
        "21slhZGCqANb",
        "xwSB5jZki3Cj",
        "mrBE3hCfJhU8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BpdJkdBssk9"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBVr18E5tse8"
      },
      "source": [
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1hkDT38hSaP"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXaz0mm2GgVO"
      },
      "source": [
        "!pip install exifread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWr5yUPXPTaM"
      },
      "source": [
        "! pip install imagehash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY01m21bPRW6"
      },
      "source": [
        "import imagehash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTJ3CrSIw2fe"
      },
      "source": [
        "MODELS = {\n",
        "    \"ViT-B/32\":       \"https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\",\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cboKZocQlSYX"
      },
      "source": [
        "! wget {MODELS[\"ViT-B/32\"]} -O model.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBRVTY9lbGm8"
      },
      "source": [
        "model = torch.jit.load(\"model.pt\").cuda().eval()\n",
        "input_resolution = model.input_resolution.item()\n",
        "context_length = model.context_length.item()\n",
        "vocab_size = model.vocab_size.item()\n",
        "\n",
        "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
        "print(\"Input resolution:\", input_resolution)\n",
        "print(\"Context length:\", context_length)\n",
        "print(\"Vocab size:\", vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6cpiIFHp9N6"
      },
      "source": [
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "from PIL import Image\n",
        "\n",
        "preprocess = Compose([\n",
        "    Resize(input_resolution, interpolation=Image.BICUBIC),\n",
        "    CenterCrop(input_resolution),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "image_mean = torch.tensor([0.48145466, 0.4578275, 0.40821073]).cuda()\n",
        "image_std = torch.tensor([0.26862954, 0.26130258, 0.27577711]).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGom156-i2kL"
      },
      "source": [
        "! pip install ftfy regex\n",
        "! wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuEd0u50cvcr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toGtcd-Ji_MD"
      },
      "source": [
        "#@title\n",
        "\n",
        "import gzip\n",
        "import html\n",
        "import os\n",
        "from functools import lru_cache\n",
        "\n",
        "import ftfy\n",
        "import regex as re\n",
        "\n",
        "\n",
        "@lru_cache()\n",
        "def bytes_to_unicode():\n",
        "    \"\"\"\n",
        "    Returns list of utf-8 byte and a corresponding list of unicode strings.\n",
        "    The reversible bpe codes work on unicode strings.\n",
        "    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n",
        "    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n",
        "    This is a signficant percentage of your normal, say, 32K bpe vocab.\n",
        "    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n",
        "    And avoids mapping to whitespace/control characters the bpe code barfs on.\n",
        "    \"\"\"\n",
        "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"¡\"), ord(\"¬\")+1))+list(range(ord(\"®\"), ord(\"ÿ\")+1))\n",
        "    cs = bs[:]\n",
        "    n = 0\n",
        "    for b in range(2**8):\n",
        "        if b not in bs:\n",
        "            bs.append(b)\n",
        "            cs.append(2**8+n)\n",
        "            n += 1\n",
        "    cs = [chr(n) for n in cs]\n",
        "    return dict(zip(bs, cs))\n",
        "\n",
        "\n",
        "def get_pairs(word):\n",
        "    \"\"\"Return set of symbol pairs in a word.\n",
        "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
        "    \"\"\"\n",
        "    pairs = set()\n",
        "    prev_char = word[0]\n",
        "    for char in word[1:]:\n",
        "        pairs.add((prev_char, char))\n",
        "        prev_char = char\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def basic_clean(text):\n",
        "    text = ftfy.fix_text(text)\n",
        "    text = html.unescape(html.unescape(text))\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def whitespace_clean(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "class SimpleTokenizer(object):\n",
        "    def __init__(self, bpe_path: str = \"bpe_simple_vocab_16e6.txt.gz\"):\n",
        "        self.byte_encoder = bytes_to_unicode()\n",
        "        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}\n",
        "        merges = gzip.open(bpe_path).read().decode(\"utf-8\").split('\\n')\n",
        "        merges = merges[1:49152-256-2+1]\n",
        "        merges = [tuple(merge.split()) for merge in merges]\n",
        "        vocab = list(bytes_to_unicode().values())\n",
        "        vocab = vocab + [v+'</w>' for v in vocab]\n",
        "        for merge in merges:\n",
        "            vocab.append(''.join(merge))\n",
        "        vocab.extend(['<|startoftext|>', '<|endoftext|>'])\n",
        "        self.encoder = dict(zip(vocab, range(len(vocab))))\n",
        "        self.decoder = {v: k for k, v in self.encoder.items()}\n",
        "        self.bpe_ranks = dict(zip(merges, range(len(merges))))\n",
        "        self.cache = {'<|startoftext|>': '<|startoftext|>', '<|endoftext|>': '<|endoftext|>'}\n",
        "        self.pat = re.compile(r\"\"\"<\\|startoftext\\|>|<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d|[\\p{L}]+|[\\p{N}]|[^\\s\\p{L}\\p{N}]+\"\"\", re.IGNORECASE)\n",
        "\n",
        "    def bpe(self, token):\n",
        "        if token in self.cache:\n",
        "            return self.cache[token]\n",
        "        word = tuple(token[:-1]) + ( token[-1] + '</w>',)\n",
        "        pairs = get_pairs(word)\n",
        "\n",
        "        if not pairs:\n",
        "            return token+'</w>'\n",
        "\n",
        "        while True:\n",
        "            bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
        "            if bigram not in self.bpe_ranks:\n",
        "                break\n",
        "            first, second = bigram\n",
        "            new_word = []\n",
        "            i = 0\n",
        "            while i < len(word):\n",
        "                try:\n",
        "                    j = word.index(first, i)\n",
        "                    new_word.extend(word[i:j])\n",
        "                    i = j\n",
        "                except:\n",
        "                    new_word.extend(word[i:])\n",
        "                    break\n",
        "\n",
        "                if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
        "                    new_word.append(first+second)\n",
        "                    i += 2\n",
        "                else:\n",
        "                    new_word.append(word[i])\n",
        "                    i += 1\n",
        "            new_word = tuple(new_word)\n",
        "            word = new_word\n",
        "            if len(word) == 1:\n",
        "                break\n",
        "            else:\n",
        "                pairs = get_pairs(word)\n",
        "        word = ' '.join(word)\n",
        "        self.cache[token] = word\n",
        "        return word\n",
        "\n",
        "    def encode(self, text):\n",
        "        bpe_tokens = []\n",
        "        text = whitespace_clean(basic_clean(text)).lower()\n",
        "        for token in re.findall(self.pat, text):\n",
        "            token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\n",
        "            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\n",
        "        return bpe_tokens\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        text = ''.join([self.decoder[token] for token in tokens])\n",
        "        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=\"replace\").replace('</w>', ' ')\n",
        "        return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozFeEgLRIT2z"
      },
      "source": [
        "import exifread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdRvgCeyc7Rj"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "images = []\n",
        "not_proc_images = []\n",
        "file_names = []\n",
        "dates = []\n",
        "hashes = {}\n",
        "duplicates = []\n",
        "duplicates_file_names = []\n",
        "for root, __, files in os.walk(\"/content/drive/MyDrive/dataset\"):\n",
        "  for f in files:\n",
        "      if f.endswith(\".jpg\"):\n",
        "         im = Image.open(os.path.join(root, f))\n",
        "         temp_hash = imagehash.average_hash(im, 8)\n",
        "         if temp_hash in hashes:\n",
        "          duplicates.append(im)\n",
        "          duplicates_file_names.append(f)\n",
        "         else:\n",
        "          file_names.append(f)\n",
        "          hashes[temp_hash] = im\n",
        "          with open(os.path.join(root, f), \"rb\") as file:\n",
        "            tags = exifread.process_file(file, details=False, stop_tag=\"DateTimeOriginal\")\n",
        "            try:\n",
        "              date_path = str(tags[\"EXIF DateTimeOriginal\"])[:10].replace(\":\", \"-\")\n",
        "              dates.append(date_path)\n",
        "            except:\n",
        "              date_path = \"no_date\"\n",
        "              dates.append(date_path)\n",
        "          not_proc_images.append(im)\n",
        "          image = preprocess(im)\n",
        "          images.append(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWzElmTgR-fk"
      },
      "source": [
        "duplicates_file_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQB9K6zthJnd"
      },
      "source": [
        "len(file_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFr6VegAJ4_W"
      },
      "source": [
        "text_descriptions = [\"This is a photo of a cat\", \n",
        "                     \"This is a photo of a dog\",\n",
        "                     \"This is a selfie\",\n",
        "                     \"This is a photo of a group of people\",\n",
        "                     \"This is a photo of nature\",\n",
        "                     \"This is photo of a meme\",\n",
        "                     \"This is a photo of food\",\n",
        "                     \"This is a photo of notes\",\n",
        "                     \"This is a photo of clothes\",\n",
        "                     \"This is a photo of a car\"\n",
        "                     ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJA5gNouxzHL"
      },
      "source": [
        "image_input = torch.tensor(np.stack(images)).cuda()\n",
        "image_input -= image_mean[:, None, None]\n",
        "image_input /= image_std[:, None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPGVzy6bIXu2"
      },
      "source": [
        "tokenizer = SimpleTokenizer()\n",
        "sot_token = tokenizer.encoder['<|startoftext|>']\n",
        "eot_token = tokenizer.encoder['<|endoftext|>']\n",
        "\n",
        "text_tokens = [[sot_token] + tokenizer.encode(desc) + [eot_token] for desc in text_descriptions]\n",
        "text_input = torch.zeros(len(text_tokens), model.context_length, dtype=torch.long)\n",
        "\n",
        "for i, tokens in enumerate(text_tokens):\n",
        "    text_input[i, :len(tokens)] = torch.tensor(tokens)\n",
        "\n",
        "text_input = text_input.cuda()\n",
        "text_input.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H41ELrADIb5R"
      },
      "source": [
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(image_input).float()\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True) # 512 -> 256 -> 1 (1/0) (N -> 512)\n",
        "    text_features = model.encode_text(text_input).float()\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "    top_probs, top_labels = text_probs.cpu().topk(3, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoPIApasMW5E"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6-FJiZ8_phg"
      },
      "source": [
        "# Результаты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvgkx6riXDf8"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPj-01U4ayCt"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRowlybAX982"
      },
      "source": [
        "for i, image in enumerate(images):\n",
        "    folder_name = [text_descriptions[index].split(' ')[-1] for index in top_labels[i].numpy()][0]\n",
        "    path = f\"/content/drive/MyDrive/results/{folder_name}/date={dates[i]}/\"\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "    file_name = f'/content/drive/MyDrive/results/{folder_name}/date={dates[i]}/{file_names[i]}'\n",
        "    cv2.imwrite(file_name, cv2.cvtColor(np.array(not_proc_images[i]), cv2.COLOR_RGB2BGR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5184VGvYwSC"
      },
      "source": [
        "for i, image in enumerate(duplicates):\n",
        "    path = f\"/content/drive/MyDrive/results/duplicates\"\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "    file_name = f'/content/drive/MyDrive/results//duplicates/{duplicates_file_names[i]}'\n",
        "    cv2.imwrite(file_name, cv2.cvtColor(np.array(duplicates[i]), cv2.COLOR_RGB2BGR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xshihongIewF"
      },
      "source": [
        "plt.figure(figsize=(50, 70))\n",
        "\n",
        "for i, image in enumerate(images):\n",
        "    plt.subplot(40, 10, 2 * i + 1)\n",
        "    plt.imshow(image.permute(1, 2, 0))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(40, 10, 2 * i + 2)\n",
        "    y = np.arange(top_probs.shape[-1])\n",
        "    plt.grid()\n",
        "    plt.barh(y, top_probs[i])\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.gca().set_axisbelow(True)\n",
        "    plt.yticks(y, [text_descriptions[index].split(' ')[-1] for index in top_labels[i].numpy()])\n",
        "    # plt.xlabel(\"probability\")\n",
        "\n",
        "plt.subplots_adjust(wspace=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrLWnHMYIig6"
      },
      "source": [
        "!pip install flask_ngrok\n",
        "!pip install flask_restplus\n",
        "!pip install exifread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FiHS1Goaif1"
      },
      "source": [
        "def process_files():\n",
        "  images = []\n",
        "  not_proc_images = []\n",
        "  file_names = []\n",
        "  dates = []\n",
        "  hashes = {}\n",
        "  duplicates = []\n",
        "  duplicates_file_names = []\n",
        "  for root, __, files in os.walk(\"/content/uploaded\"):\n",
        "    for f in files:\n",
        "        if f.endswith(\".jpg\"):\n",
        "          im = Image.open(os.path.join(root, f))\n",
        "          temp_hash = imagehash.average_hash(im, 8)\n",
        "          if temp_hash in hashes:\n",
        "            duplicates.append(im)\n",
        "            duplicates_file_names.append(f)\n",
        "          else:\n",
        "            file_names.append(f)\n",
        "            hashes[temp_hash] = im\n",
        "            with open(os.path.join(root, f), \"rb\") as file:\n",
        "              tags = exifread.process_file(file, details=False, stop_tag=\"DateTimeOriginal\")\n",
        "              try:\n",
        "                date_path = str(tags[\"EXIF DateTimeOriginal\"])[:10].replace(\":\", \"-\")\n",
        "                dates.append(date_path)\n",
        "              except:\n",
        "                date_path = \"no_date\"\n",
        "                dates.append(date_path)\n",
        "            not_proc_images.append(im)\n",
        "            image = preprocess(im)\n",
        "            images.append(image)\n",
        "\n",
        "  text_descriptions = [\"This is a photo of a cat\", \n",
        "                     \"This is a photo of a dog\",\n",
        "                     \"This is a selfie\",\n",
        "                     \"This is a photo of a group of people\",\n",
        "                     \"This is a photo of nature\",\n",
        "                     \"This is photo of a meme\",\n",
        "                     \"This is a photo of food\",\n",
        "                     \"This is a photo of notes\",\n",
        "                     \"This is a photo of clothes\",\n",
        "                     \"This is a photo of a car\"\n",
        "                     ]\n",
        "  image_input = torch.tensor(np.stack(images)).cuda()\n",
        "  image_input -= image_mean[:, None, None]\n",
        "  image_input /= image_std[:, None, None]\n",
        "  tokenizer = SimpleTokenizer()\n",
        "  sot_token = tokenizer.encoder['<|startoftext|>']\n",
        "  eot_token = tokenizer.encoder['<|endoftext|>']\n",
        "\n",
        "  text_tokens = [[sot_token] + tokenizer.encode(desc) + [eot_token] for desc in text_descriptions]\n",
        "  text_input = torch.zeros(len(text_tokens), model.context_length, dtype=torch.long)\n",
        "\n",
        "  for i, tokens in enumerate(text_tokens):\n",
        "      text_input[i, :len(tokens)] = torch.tensor(tokens)\n",
        "\n",
        "  text_input = text_input.cuda()\n",
        "  text_input.shape\n",
        "  with torch.no_grad():\n",
        "    image_features = model.encode_image(image_input).float()\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True) # 512 -> 256 -> 1 (1/0) (N -> 512)\n",
        "    text_features = model.encode_text(text_input).float()\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "    top_probs, top_labels = text_probs.cpu().topk(3, dim=-1)\n",
        "  for i, image in enumerate(images):\n",
        "    folder_name = [text_descriptions[index].split(' ')[-1] for index in top_labels[i].numpy()][0]\n",
        "    path = f\"/content/drive/MyDrive/results/{folder_name}/date={dates[i]}/\"\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "    file_name = f'/content/drive/MyDrive/results/{folder_name}/date={dates[i]}/{file_names[i]}'\n",
        "    cv2.imwrite(file_name, cv2.cvtColor(np.array(not_proc_images[i]), cv2.COLOR_RGB2BGR))\n",
        "  for i, image in enumerate(duplicates):\n",
        "    path = f\"/content/drive/MyDrive/results/duplicates\"\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "    file_name = f'/content/drive/MyDrive/results//duplicates/{duplicates_file_names[i]}'\n",
        "    cv2.imwrite(file_name, cv2.cvtColor(np.array(duplicates[i]), cv2.COLOR_RGB2BGR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiEKJGraVMn-"
      },
      "source": [
        "from flask import Flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "app.secret_key = \"secret key\"\n",
        "\n",
        "import werkzeug\n",
        "werkzeug.cached_property = werkzeug.utils.cached_property\n",
        "from flask_restplus import Api, Resource\n",
        "from werkzeug.datastructures import FileStorage\n",
        "\n",
        "import os\n",
        "\n",
        "api = Api(app)\n",
        "upload_parser = api.parser()\n",
        "upload_parser.add_argument('file',\n",
        "                           location='files',\n",
        "                           type=FileStorage)\n",
        "\n",
        "#here u add function that execute group images\n",
        "@api.route('/upload/')\n",
        "@api.expect(upload_parser)\n",
        "class File(Resource):\n",
        "    def post(self):\n",
        "        args = upload_parser.parse_args()\n",
        "        file = args.get('file')\n",
        "        file.save('/content/zip_uploaded.zip')\n",
        "        preprocessing()\n",
        "        process_files()\n",
        "                        ##HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRVqzBX5VPGM"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "#unzip\n",
        "def preprocessing():\n",
        "  shutil.unpack_archive('/content/zip_uploaded.zip', '/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTcz-k3KVRe9"
      },
      "source": [
        "#enter point\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}